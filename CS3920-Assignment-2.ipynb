{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS3920 Assignment 2\n",
    "\n",
    "1. Install the needed libraries into the current environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.0-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.3-cp311-cp311-win_amd64.whl.metadata (168 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.7-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kurisu\\projects\\cs3920-cw2\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.0.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kurisu\\projects\\cs3920-cw2\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kurisu\\projects\\cs3920-cw2\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading scikit_learn-1.6.0-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.7/11.1 MB 9.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.1 MB 10.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.7/11.1 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 8.9 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.10.0-cp311-cp311-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.6/8.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.4/8.0 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.5/8.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.3/8.0 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.0 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 7.3 MB/s eta 0:00:00\n",
      "Downloading numpy-2.2.0-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.9/12.9 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.0/12.9 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.9/12.9 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.0/12.9 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.9 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp311-cp311-win_amd64.whl (219 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.3-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 7.8 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached kiwisolver-1.4.7-cp311-cp311-win_amd64.whl (56 kB)\n",
      "Using cached pillow-11.0.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, pyparsing, pillow, numpy, kiwisolver, joblib, fonttools, cycler, scipy, contourpy, scikit-learn, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 joblib-1.4.2 kiwisolver-1.4.7 matplotlib-3.10.0 numpy-2.2.0 pillow-11.0.0 pyparsing-3.2.0 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the data set into Python using, e.g., load_wine or genfromtxt, as appropriate. In the case of the USPS dataset, merge the original training and test sets into one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import numpy as np\n",
    "\n",
    "uspsZip = {}\n",
    "wine = load_wine()\n",
    "\n",
    "# Load data from both files\n",
    "test_data = np.genfromtxt(\"zip.test\", delimiter=\" \", usecols=np.arange(1, 257))\n",
    "train_data = np.genfromtxt(\"zip.train\", delimiter=\" \", usecols=np.arange(1, 257))\n",
    "\n",
    "# Load targets from both files\n",
    "test_target = np.genfromtxt(\"zip.test\", delimiter=\" \", usecols=0, dtype='int')\n",
    "train_target = np.genfromtxt(\"zip.train\", delimiter=\" \", usecols=0, dtype='float').astype(int)\n",
    "\n",
    "# Combine the two files\n",
    "uspsZip['data'] = np.vstack((test_data, train_data))\n",
    "uspsZip['target'] = np.concatenate((test_target, train_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Divide the dataset into a training set and a test set. You may use the\n",
    "function train_test_split. Use your birthday in the format DDMM as\n",
    "random_state (omit leading zeros if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(wine.data, wine.target, random_state=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_zip_train, X_zip_test, y_zip_train, y_zip_test = train_test_split(uspsZip[\"data\"], uspsZip[\"target\"], random_state=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set for ZIP Codes: 0.9708874181720943\n",
      "Accuracy on training set for Wine dataset: 0.6541310541310541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "zip_score = np.mean(cross_val_score(svc, X_zip_train, y_zip_train))\n",
    "wine_score = np.mean(cross_val_score(svc, X_wine_train, y_wine_train))\n",
    "\n",
    "print(f\"Accuracy on training set for ZIP Codes: {zip_score}\")\n",
    "print(f\"Accuracy on training set for Wine dataset: {wine_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Find the test error rate of the SVM with the default values of parameters,\n",
    "compare it with the estimate obtained in the previous task (task 3), and\n",
    "write your observations in a markdown cell of your Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error-rate for ZIP Code dataset: 2.8817204301075208%\n",
      "Error-rate for Wine dataset: 31.111111111111114%\n",
      "Accuracy for ZIP Code dataset: 97.11827956989248%\n",
      "Accuracy for Wine dataset: 68.88888888888889%\n"
     ]
    }
   ],
   "source": [
    "svc.fit(X_zip_train, y_zip_train)\n",
    "zip_acc = svc.score(X_zip_test, y_zip_test) * 100\n",
    "\n",
    "svc.fit(X_wine_train, y_wine_train)\n",
    "wine_acc = svc.score(X_wine_test, y_wine_test) * 100\n",
    "\n",
    "print(f\"Error-rate for ZIP Code dataset: {100 - zip_acc}%\")\n",
    "print(f\"Error-rate for Wine dataset: {100 - wine_acc}%\")\n",
    "\n",
    "print(f\"Accuracy for ZIP Code dataset: {zip_acc}%\")\n",
    "print(f\"Accuracy for Wine dataset: {wine_acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a pipeline for SVM involving data normalization and SVC, and\n",
    "use grid search and cross-validation to tune parameters C and gamma for\n",
    "the pipeline, avoiding data snooping and data leakage. You may use\n",
    "the scikit-learn class GridSearchCV (along with other scikit-learn\n",
    "classes). Experiment with different ways of doing normalization (such\n",
    "as StandardScaler, MinMaxScaler, RobustScaler, and Normalizer).\n",
    "Which ways are appropriate for either dataset? (The answer, which should\n",
    "be written in your Jupyter notebook, may depend on the results that you\n",
    "obtain for the next task.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler, RobustScaler, StandardScaler\n",
    "\n",
    "normalisers = [Normalizer(), MinMaxScaler(), RobustScaler(), StandardScaler()]\n",
    "grid_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "def normalise(meth, gridVals, X_test, y_test, X_train, y_train):\n",
    "    pipeline = make_pipeline(meth, SVC())\n",
    "    pipe_param = {\"svc__C\": gridVals, \"svc__gamma\": gridVals}\n",
    "    g_search = GridSearchCV(pipeline, param_grid=pipe_param, cv=len(gridVals), n_jobs=-1)\n",
    "    g_search.fit(X_train, y_train)\n",
    "\n",
    "    return (g_search.score(X_test, y_test), g_search.best_score_, g_search.best_params_), g_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9555555555555556, np.float64(0.8880341880341881), {'svc__C': 100, 'svc__gamma': 100}), (1.0, np.float64(0.9772079772079773), {'svc__C': 0.1, 'svc__gamma': 1}), (1.0, np.float64(0.9703703703703702), {'svc__C': 0.1, 'svc__gamma': 0.1}), (1.0, np.float64(0.9772079772079773), {'svc__C': 1, 'svc__gamma': 0.01})]\n",
      "[GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('normalizer', Normalizer()),\n",
      "                                       ('svc', SVC())]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'svc__C': [0.01, 0.1, 1, 10, 100],\n",
      "                         'svc__gamma': [0.01, 0.1, 1, 10, 100]}), GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('minmaxscaler', MinMaxScaler()),\n",
      "                                       ('svc', SVC())]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'svc__C': [0.01, 0.1, 1, 10, 100],\n",
      "                         'svc__gamma': [0.01, 0.1, 1, 10, 100]}), GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('robustscaler', RobustScaler()),\n",
      "                                       ('svc', SVC())]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'svc__C': [0.01, 0.1, 1, 10, 100],\n",
      "                         'svc__gamma': [0.01, 0.1, 1, 10, 100]}), GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                                       ('svc', SVC())]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'svc__C': [0.01, 0.1, 1, 10, 100],\n",
      "                         'svc__gamma': [0.01, 0.1, 1, 10, 100]})]\n"
     ]
    }
   ],
   "source": [
    "wine_grids = []\n",
    "wine_saved_norm = []\n",
    "\n",
    "for i in normalisers:\n",
    "    grid, norm = normalise(i, grid_values, X_wine_test, y_wine_test, X_wine_train, y_wine_train)\n",
    "    wine_grids.append(grid)\n",
    "    wine_saved_norm.append(norm)\n",
    "\n",
    "print(wine_grids)\n",
    "print(wine_saved_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m zip_saved_norm \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m normalisers:\n\u001b[1;32m----> 5\u001b[0m     grid, norm \u001b[38;5;241m=\u001b[39m \u001b[43mnormalise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_zip_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_zip_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_zip_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_zip_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     zip_grids\u001b[38;5;241m.\u001b[39mappend(grid)\n\u001b[0;32m      7\u001b[0m     zip_saved_norm\u001b[38;5;241m.\u001b[39mappend(norm)\n",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m, in \u001b[0;36mnormalise\u001b[1;34m(meth, gridVals, X_test, y_test, X_train, y_train)\u001b[0m\n\u001b[0;32m      9\u001b[0m pipe_param \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvc__C\u001b[39m\u001b[38;5;124m\"\u001b[39m: gridVals, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvc__gamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: gridVals}\n\u001b[0;32m     10\u001b[0m g_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid\u001b[38;5;241m=\u001b[39mpipe_param, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(gridVals), n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mg_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (g_search\u001b[38;5;241m.\u001b[39mscore(X_test, y_test), g_search\u001b[38;5;241m.\u001b[39mbest_score_, g_search\u001b[38;5;241m.\u001b[39mbest_params_), g_search\n",
      "File \u001b[1;32mc:\\Users\\Kurisu\\Projects\\CS3920-CW2\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kurisu\\Projects\\CS3920-CW2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1023\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1017\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1018\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1019\u001b[0m     )\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1023\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Kurisu\\Projects\\CS3920-CW2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1570\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1570\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kurisu\\Projects\\CS3920-CW2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:969\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    965\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    966\u001b[0m         )\n\u001b[0;32m    967\u001b[0m     )\n\u001b[1;32m--> 969\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    989\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kurisu\\Projects\\CS3920-CW2\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kurisu\\Projects\\CS3920-CW2\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\Kurisu\\Projects\\CS3920-CW2\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kurisu\\Projects\\CS3920-CW2\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "zip_grids = []\n",
    "zip_saved_norm = []\n",
    "\n",
    "for i in normalisers:\n",
    "    grid, norm = normalise(i, grid_values, X_zip_test, y_zip_test, X_zip_train, y_zip_train)\n",
    "    zip_grids.append(grid)\n",
    "    zip_saved_norm.append(norm)\n",
    "\n",
    "print(zip_grids)\n",
    "print(zip_saved_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
